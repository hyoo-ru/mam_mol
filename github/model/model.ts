namespace $ {
	
	// Make new tokens: https://github.com/settings/personal-access-tokens/new?name=$mol_github_model&user_models=read
	export const $mol_github_model_keys = [
		
		'11AADME3A07jh1teLjee8r_O7MKyAF8rbdIlhk4OwsJHaCnh4CjDNxn1nLNAvW2Hy6OSTIYABWQyp0rOHt',
		'11AADME3A0q6w8EFz9G9aa_byqEpTuWUa63PKoSAwN1eVi2GyGJ4SxYhm9OhAc2DCTANK2ULBQpQgUu6D9',
		'11AADME3A0RsfJpmuZfl4r_Nw6G3v7vDgnrqDxmlgF6Gyj9YawDfTqatNUxhwPjzWwYYGIORGETiUtMOmR',
		'11AADME3A0meTYzVZaOtJF_LrdN2tIDycZHDBN3560V3S2ZWpo07uATZON0XUYF2ZFFC3X2OHSwdUcVfUe',
		'11AADME3A0myGzFwrNHkV0_InRujMNsqM7cLUWDvKCW5GRy2waC7fHXuSJdzW0mrwvX7VP4I2MoGXRXF6w',
		'11AADME3A0LF4GM8Qam5xH_LFLHQqgcmudC8eyKLEqc4l5xDPcplSxAcEA3j8BO4MYTAE6FOROqFIuhGfR',
		'11AADME3A0KUqaRrYVSMzf_rYLJd83byQ1HN8KOIzVnHPBvW6VPei911NJgPucm1hRETR55VB3mdyw2ezI',
		'11AADME3A0exOKaaQLYR2b_2JKJDHVAWxoqRPlGcugBHNapcZWT9awRic8iBmgOirXRVC5X7ILtz6KDffv',
		'11AADME3A071WbELDi8THV_v3dkQtbYpSGjUXeWT6dAiPBf5a5b0KDr0E029T6P4CsZOOYO3DPpopBkodL',
		'11AADME3A0L5oFWUKk62fr_Dcbcn1ZcNBwWaLfbHzlgueGcxBEO5FoOieoowhJ6Q1zIWIIYZBG7XI16O4H',
		
		'11ABRVBSY0f8VzkzaCnFmy_PMfBlJqT7DuvxfzbYRUlLOZJenEqBvNpGP7uQKCDOaO6ZKS4DFCG0qYxy2I',
		'11ABRVBSY0no18F8ngCYoa_60v1HSbYVeEZ2d3tf1ix2Kq7G8ZRYaFFiHImNxERTkqJ5CWMQ6VmjH7ic86',
		'11ABRVBSY0acYIFJ0b9cAV_0wPJI2JxZgLYasswZjIUMQqxnYcRAUEG68xtsh9uQtNZDYU37IS5GBobX8v',
		'11ABRVBSY0KhLO9yDqoqMM_B328qDB5kCHqgAJNw3q1MW48gHQ9XYAnnRQFlXkE1MQGX3S5TOK6k4od8C8',
		'11ABRVBSY04TXJfmvdflXC_o9UQLVNWbPWzaqaaZll9fFn9QLAZotSwi18clpeaaYkTQEHQSW3yvrSAsCb',
		'11ABRVBSY0n7osgrVkUT0l_PQadBMEjSXLOGZGwuu5wVXydSnwxboWUAxAIdXgXP9hRVQOKM5UNsJaKk0M',
		'11ABRVBSY0Zctkh9fg9Cpl_nqCk5TSio22hgtvAWqYzGvlsfaIH9e66ery772pkCW0C7EJA7HJrPGxIYQy',
		'11ABRVBSY0XbD5DK094oOY_8mmeflfbf4mu48bWk7OFQvrxxPXp5gFCxO5PUokPwsw2LZRC6DZSujLHCVt',
		'11ABRVBSY0AGZyClxdqZDx_gseo5RI9HKRPvlQtRFmmR5An2jaRna9glpzv40wi7MZCCCDAVIWk3l1Nwp9',
		'11ABRVBSY0SvjU9l1d7DXU_LOZfXdIZuupZCmu1FA4NGUOy572G8ZJ6pzYyzu9RsWfG7HLRMLYIIIE54Mp',
		
		'11AACDCYQ0R6jhkMIx4zY4_OlEwnePW3UFhkNsJuyAweBPsHtqlhBW7WD69mWjuuYTTAYOTX7KL4WK1Yg7',
		'11AACDCYQ0Ai0LkLKrp9kE_D10SuqSODWeGWvA4Rgux6ZXs2AEwl3IqpElNGRI7JG0ZIGVKV5RaUDAchxe',
		'11AACDCYQ0c94yhWtZq2HX_YFms0ToLulxGTnr80ndTsHZIOfNMl8QdLmoKL75fZ3oK6JN3NOKsnxMZ1qu',
		'11AACDCYQ0DkrjD2bmmKpL_PcrQXvrbiEnJl0oazFx70p9wdCXd2rP5DhazexPAcygLGKIOQRXeeCXsP7B',
		'11AACDCYQ0IMIYCLcX3xrO_901enZ0EKxk48giaCI7vkIHZgdOpqrvPyHiF4t02klvCLI7OVRE3uqJ3PKf',
		'11AACDCYQ0WIjNWbjdJclE_KKiTwAIGNcbpPIO6SJfBxbuUVixxug7QH5KPRcMXAYv3ZOROGOVFvj4GzzG',
		'11AACDCYQ0tKWudX3T6T6l_wGiLSmI6aYR7Wf5ZXFukZdPuUL7lpGpBIzkm8CSxcaoJQT7GDAU2PtnWWDj',
		'11AACDCYQ0Ocm4JD37TfHG_0KPjGl3ucMm4ozREvzF1QNY3UECaZNh3SiY49AUzJgGNITGLVH2LdHhz7PT',
		'11AACDCYQ0R5HgcrZOxDwc_dgCK0jETB27GYYCmh1YMfdE5dPuLNZ1DLiIDi2tQnr0IGUX5WFRNa9oTaSw',
		
		'11AZC2M3A02nw2Q86BPmYQ_yl2RFA1RXRuEVWU0ufTjBXl12SvUWyeZxZ9cbZRuind6QWI65J4tXbAfF2p',
		'11AZC2M3A0gcGTDvExPjEL_m1itogjz24QDTxT0zJTpDJmyZ3sSKO1UXapXfw7q0BLMUIOXP3SB7zRfavu',
		'11AZC2M3A0Y1oDGiEjDZ1g_t5ry6SPyckVwZvBQvBke09QbNMF8rG1TXdcops2BiDmKDYKOOCV58edg7VY',
		'11AZC2M3A00bI3vc5JPaA2_MZGbctgtp5KEdBD2dYVW7MaQ2Fqiw8UrIpHKZp8xnczJGHTTJQPa9QxXjrc',
		'11AZC2M3A0fGlQkvashsda_CuaNQlzrajBrj82VlUzZQ67Qgq9X3QudJ9S3SM3wnzvNIQRQARZoClezK3C',
		'11AZC2M3A06Zat4wc9fotV_0gdnr4cGXfzD2wTkBIr5QYyj3ErxgMcHJerQb81AtnqBSYKBHIEzBXbqzQr',
		'11AZC2M3A0V1JUeQY0eOov_rrWyENLMO5Sxa4IEPbZMLippdb8TQi531bmfJQBBaCfQHIC5PQFFwUp49DW',
		'11AZC2M3A0G89rDbsh2k20_l6kEuOm10kV86RGIp1s5wQ1n6kLe0WFgeCHLthnGNSyDSIBNNC6Q7kjGrem',
		'11AZC2M3A0tAUQ7dX2dnaI_hvDm1d0lxDpHXkYx1khtJyidfjREBvg2qssXurwxihAHBEMII5T7l5WrXI9',
		'11AZC2M3A0VPRCdsbErhom_W0wrECR4sbXQZLlG966rsb1G65pOXJGbk4uaV0zUNpMZPDBW5DSTZyRTCJy',
		'11AZC2M3A06fZVQGXETeaM_KIU5iEeb6UtpBrGZMOG6kQc1r32A5Xh1uxAMdmZRwkHICW2HJMAHcv236fa',
		'11AZC2M3A0QyPnQfDarLu5_x6eKghOwMB3yX2KPPVGvD3PKKuY5QiK7gJ4eoPiYCSwOBQVU2P6EOzN75xf',
		'11AZC2M3A0VW9BdSxec56G_P3YnEAFXcC7IMauK8nhxHwFNS09AgIisAuy9Kft19o2LAHR5RXQyMHIl9yQ',
		'11AZC2M3A0P4o9D1flcC0S_f2NS5FSSogJoFsocKShuv4m7ghDBamKRgPvPqACGEejJRU2BBE2gymGHhk1',
		'11AZC2M3A0cI704OJ5EVfc_8c1ggPeodHoWEY8lMHH9cvKLGyGvGbgzW7tr4V7E5ITT7RDCHJYzNZoXxGF',
		'11AZC2M3A0yFNB07z5VFbp_RtEMVMcdKpfFgn0ls2v3hlcJDsIs6v7e64TXSW2muOK5RPKAJ3WxdZS2vzT',
		'11AZC2M3A06KL2qd1GmlIB_a7tt0VJaKLybMxJLdJ6JPk6iBgNaECXJsFd5FyCl4nSSQT3QSG4ETLYFOwj',
		'11AZC2M3A0Ui6RqKCiBn6X_6S4OnreMp6Au5JSRwfcWop1SiHV9ooFsBHhYkFEiErAQYHDENGGzLmL1aD9',
		'11AZC2M3A0hk74xKy52Egx_jYVCEjt9jpT2peCB0qT7JrnSX1a075ZASxKTzaV3KeqTTV5A7SRNxkaElKn',
		'11AZC2M3A021XEPByvPlBg_rKr4RNMcfeflEKrL5qGxDieXMKLlf4S6FWvtUUzIYaoOK63JXVBv8XPAfi5',
		'11AZC2M3A0yK6fYUgjj79M_5yu4OE4RdeFk8IoY3kcOC1xemTvjB1B8tOzA1KPmqQSX37EDQIOIuRjf9jF',
		
	].map( str => `github_pat_${str}` )
	
	export const $mol_github_model_polyglots = [
		// 'openai/gpt-4.1', // 50/D too slow
		// 'openai/gpt-4o', // 50/D bad resp
		'openai/gpt-4.1-mini', // 150/D
		// 'openai/gpt-4o-mini', // 150/D bad resp
		// 'openai/gpt-4.1-nano', // 150/D bad resp
	]
	
	const System = $mol_data_record({
		role: $mol_data_const( 'system' ),
		content: $mol_data_string,
	})
	
	const Assistant = $mol_data_record({
		role: $mol_data_const( 'assistant' ),
		content: $mol_data_nullable( $mol_data_string ),
		tool_calls: $mol_data_optional( $mol_data_array( $mol_data_record({
			type: $mol_data_const( 'function' ),
			id: $mol_data_string,
			function: $mol_data_record({
				name: $mol_data_string,
				arguments: $mol_data_string,
			}),
		}) ) ),
	})
	
	const User = $mol_data_record({
		role: $mol_data_const( 'user' ),
		content: $mol_data_string,
	})
	
	const Tool = $mol_data_record({
		role: $mol_data_const( 'tool' ),
		// name: $mol_data_string,
		tool_call_id: $mol_data_string,
		content: $mol_data_string,
	})
	
	const Message = $mol_data_variant( Assistant, User, Tool )
	
	const Resp = $mol_data_record({
		choices: $mol_data_array( $mol_data_record({
			message: Assistant,
		}) ),
	})
	
	const RespFail = $mol_data_record({
		error: $mol_data_record({
			message: $mol_data_string,
		}),
	})
	
	
	type Primitive< Type extends 'string' | 'number' | 'integer' | 'boolean' > = Readonly<{
		type: Type
		enum?: Type[]
	}>
	
	type Obj< Params extends Record< string, Type > > = Readonly<{
		type: 'object'
		parameters: Params
		required: keyof Params
	}>
	
	type List< Item extends Type > = Readonly<{
		type: 'array'
		items: Item
	}>
	
	type Type = Obj<any> | List<any> | Primitive<any>
	
	
	/**
	 * Github hosted LLM API.
	 */
	export class $mol_github_model extends $mol_object {
		
		// STATIC STATE
		
		/** Model names from https://github.com/marketplace/models */
		@ $mol_memo.method
		names() {
			return this.$.$mol_github_model_polyglots
		}
		
		/** System rules */
		rules() {
			return ''
		}
		
		/** List of callable functions */
		@ $mol_memo.method
		tools() {
			return new Map< string, {
				descr: string
				params: Obj<any>
				func: Function
			} >()
		}
		
		// DYNAMIC STATE
		
		/** Additional model query params */
		@ $mol_mem
		params( next?: {}) {
			$mol_wire_solid()
			return next ?? {}
		}
		
		/** Dialog history */
		@ $mol_mem
		history( next?: typeof Message.Value[] ) {
			$mol_wire_solid()
			return next ?? []
		}
		
		// ACTIONS
		
		/** Independent copy of current state. */
		@ $mol_action
		fork() {
			
			const fork = $mol_github_model.make({
				// static state
				names: $mol_const( this.names() ),
				rules: $mol_const( this.rules() ),
				tools: $mol_const( this.tools() ),
			})
			
			// dynamic state
			fork.params( this.params() )
			fork.history( this.history() )
			
			return fork
		}
		
		/** One-shot stateless prompting */
		@ $mol_action
		shot( prompt: any, context?: any, params?: {} ) {
			const fork = this.fork()
			if( params ) fork.params({ ... this.params(), ... params })
			if( context ) fork.tell( context )
			fork.ask( prompt )
			return fork.response()
		}
		
		/** Add user prompt */
		@ $mol_action
		ask( text: any ) {
			this.history([
				... this.history(),
				{
					role: "user",
					content: JSON.stringify( text ),
				}
			])
			return this
		}
		
		/** Add assistant context */
		@ $mol_action
		tell( text: any ) {
			this.history([
				... this.history(),
				{
					role: "assistant",
					content: JSON.stringify( text ),
				}
			])
			return this
		}
		
		/** Add tools answer */
		@ $mol_action
		answer( id: string, data: any ) {
			
			const history = this.history()
			
			const index = 1 + history.findIndex( msg => msg.role === 'tool' && msg.tool_call_id === id )
			if( !index ) this.$.$mol_fail( new Error( 'Wrong tool call id', { cause: id } ) )
			
			this.history([
				... history.slice( 0, index ),
				{
					role: "tool",
					tool_call_id: id,
					content: JSON.stringify( data ),
				},
				... history.slice( index ),
			])
			return this
		}
		
		// INFERENCE
		
		@ $mol_mem_key
		request_body( model: string ) {
			return JSON.stringify({
				model,
				stream: false,
				response_format: { type: 'json_object' },
				messages: [
					{ role: 'system', content: this.rules() },
					... this.history(),
				],
				tools: [ ... this.tools() ].map( ([ name, info ])=> ({
					type: "function",
					function: {
						name,
						description: info.descr,
						strict: true,
						parameters: info.params,
					},
				}) ),
				... this.params(),
			})
		}
		
		request( model: string, key: string ) {
			return Resp( this.$.$mol_fetch.json(
				`https://models.github.ai/inference/chat/completions`,
				{
					method: 'POST',
					headers: {
						'Authorization': 'Bearer ' + key,
						'Content-Type': 'application/json',
					},
					body: this.request_body( model )
				}
			) as any )
		}
		
		/** Last response from LLM */
		@ $mol_mem
		response() {
			
			const history = this.history()
			
			const last = history.at(-1)
			if( last?.role !== 'user' ) return null
			
			const models = this.$.$mol_array_shuffle_sync( this.names() )
			const keys = this.$.$mol_array_shuffle_sync( $mol_github_model_keys )
			
			for( const model of models ) for( const key of keys ) {
			
				try {
					
					const resp = this.request( model, key )
					const message = resp.choices[0].message
					this.history([ ... history, message ])
					return JSON.parse( message.content ?? 'null' )
				
				} catch( error: any ) {

					const resp = error.cause as $mol_fetch_response
					if( !resp ) return $mol_fail_hidden( error )
						
					if( resp.code() === 429 ) continue // rate limit
					
					if( resp.code() === 400 ) {
						const message = RespFail( resp.json() as any ).error.message
						this.history([ ... history, { role: 'assistant', content: 'ðŸ“› ' + message } ])
						$mol_fail( new Error( message ) )
					}
					
					$mol_fail_hidden( error )

				}
			
			}
			
			return this.$.$mol_fail( new Error( 'No alive token' ) )
			
		}
		
	}
	
}
